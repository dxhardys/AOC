{
  "_cqa_text_report":
    {
      "_objects":
        {
          "image_vec_align":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/vec_align.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x32_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_128.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_4x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x64_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_128.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_4x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_8x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/8x32_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_2x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_2x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_256.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_1x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_4x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x64_512.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_row_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/row_maj.svg",
              "size":
                {
                  "x": 500,
                },
            },
          "image_col_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/col_maj.svg",
              "size":
                {
                  "x": 500,
                },
            },
        },
      "AVG":
        {
          "hint":
            [
              {
                "details": "These instructions generate more than one micro-operation and only one of them can be decoded during a cycle and the extra micro-operations increase pressure on execution units.\n - VCOMISS: 1 occurrences\n - VCVTTSS2SI: 12 occurrences\n",
                "title": "Complex instructions",
                "txt": "Detected COMPLEX INSTRUCTIONS.\n",
              },
              {
                "workaround": "Avoid mixing data with different types. In particular, check if the type of constants is the same as array elements. Use double instead of single precision only when/where needed by numerical stability and avoid mixing precision. In C/C++, FP constants are double precision by default and must be suffixed by 'f' to make them single precision.",
                "details": " - VCVTSS2SD (FP32 to FP64, scalar): 12 occurrences\n - VCVTTSS2SI (FP32 to INT32/64, scalar): 12 occurrences\n",
                "title": "Conversion instructions",
                "txt": "Detected expensive conversion instructions.",
              },
              {
                "title": "Type of elements and instruction set",
                "txt": "85 SSE or AVX instructions are processing arithmetic or math operations on single precision FP elements in scalar mode (one at a time).\n12 SSE or AVX instructions are processing arithmetic or math operations on double precision FP elements in scalar mode (one at a time).\n",
              },
              {
                "title": "Matching between your loop (in the source code) and the binary loop",
                "txt": "The binary loop is composed of 120 FP arithmetical operations:\n - 48: addition or subtraction (24 inside FMA instructions)\n - 48: multiply (24 inside FMA instructions)\n - 24: divide\nThe binary loop is loading 48 bytes (12 single precision FP elements).\nThe binary loop is storing 8 bytes (2 single precision FP elements).",
              },
              {
                "title": "Arithmetic intensity",
                "txt": "Arithmetic intensity is 2.14 FP operations per loaded or stored byte.",
              },
            ],
          "expert":
            [
              {
                "title": "General properties",
                "txt": "nb instructions    : 147.50\nnb uops            : 160\nloop length        : 664.50\nused x86 registers : 11\nused mmx registers : 0\nused xmm registers : 16\nused ymm registers : 0\nused zmm registers : 0\nnb stack references: 5\nADD-SUB / MUL ratio: 1.00\n",
              },
              {
                "title": "Front-end",
                "txt": "MACRO FUSION NOT POSSIBLE\nmicro-operation queue: 26.67 cycles\nfront end            : 26.67 cycles\n",
              },
              {
                "title": "Back-end",
                "txt": "       | ALU0/BRU0 | ALU1 | ALU2  | ALU3 | BRU1 | AGU0 | AGU1 | AGU2 | FP0   | FP1   | FP2   | FP3   | FP4  | FP5\n------------------------------------------------------------------------------------------------------------------\nuops   | 1.25      | 1.00 | 13.00 | 1.00 | 1.25 | 4.33 | 4.33 | 4.33 | 36.50 | 36.50 | 24.75 | 24.75 | 7.00 | 7.00\ncycles | 1.25      | 1.00 | 13.00 | 1.00 | 1.25 | 4.33 | 4.33 | 4.33 | 36.50 | 36.50 | 24.75 | 24.75 | 7.00 | 7.00\n\nExecution ports to units layout:\n - ALU0/BRU0: ALU\n - ALU1: ALU\n - ALU2: ALU\n - ALU3: ALU\n - BRU1: \n - AGU0 (256 bits): store address, load\n - AGU1 (256 bits): store address, load\n - AGU2 (256 bits): store address, load\n - FP0 (256 bits): VPU, DIV/SQRT\n - FP1 (256 bits): VPU, DIV/SQRT\n - FP2 (256 bits): VPU\n - FP3 (256 bits): VPU\n - FP4 (256 bits): FP store data\n - FP5 (256 bits): FP store data\n\nCycles executing div or sqrt instructions: 84.00\nLongest recurrence chain latency (RecMII): 0.00\n",
              },
              {
                "title": "Cycles summary",
                "txt": "Front-end : 26.67\nDispatch  : 36.50\nDIV/SQRT  : 84.00\nData deps.: 0.00\nOverall L1: 84.00\n",
              },
              {
                "title": "Vectorization ratios",
                "txt": "INT\nall    : 0%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 0%\nFP\nall     : 3%\nload    : 0%\nstore   : 0%\nmul     : 0%\nadd-sub : 0%\nfma     : 0%\ndiv/sqrt: 0%\nother   : 13%\nINT+FP\nall     : 2%\nload    : 0%\nstore   : 0%\nmul     : 0%\nadd-sub : 0%\nfma     : 0%\ndiv/sqrt: 0%\nother   : 9%\n",
              },
              {
                "title": "Vector efficiency ratios",
                "txt": "INT\nall    : 12%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 12%\nFP\nall     : 14%\nload    : 12%\nstore   : 25%\nmul     : 12%\nadd-sub : 18%\nfma     : 12%\ndiv/sqrt: 12%\nother   : 17%\nINT+FP\nall     : 14%\nload    : 12%\nstore   : 25%\nmul     : 12%\nadd-sub : 18%\nfma     : 12%\ndiv/sqrt: 12%\nother   : 16%\n",
              },
              {
                "title": "Cycles and memory resources usage",
                "txt": "Assuming all data fit into the L1 cache, each iteration of the binary loop takes 84.00 cycles. At this rate:\n - 0% of peak load performance is reached (0.57 out of 96.00 bytes loaded per cycle (GB/s @ 1GHz))\n - 0% of peak store performance is reached (0.10 out of 64.00 bytes stored per cycle (GB/s @ 1GHz))\n",
              },
            ],
          "header":
            [
            "2% of peak computational performance is used (1.43 out of 48.00 FLOP per cycle (GFLOPS @ 1GHz))",
            ],
          "brief":
            [
            ],
          "gain":
            [
              {
                "workaround": " - Try another compiler or update/tune your current one:\n  * recompile with fassociative-math (included in Ofast or ffast-math) to extend loop vectorization to FP reductions.\n - Remove inter-iterations dependences from your loop and make it unit-stride:\n  * If your arrays have 2 or more dimensions, check whether elements are accessed contiguously and, otherwise, try to permute loops accordingly:\nC storage order is row-major: for(i) for(j) a[j][i] = b[j][i]; (slow, non stride 1) => for(i) for(j) a[i][j] = b[i][j]; (fast, stride 1)<<image_row_maj>>\n  * If your loop streams arrays of structures (AoS), try to use structures of arrays instead (SoA):\nfor(i) a[i].x = b[i].x; (slow, non stride 1) => for(i) a.x[i] = b.x[i]; (fast, stride 1)\n",
                "details": "Store and arithmetical SSE/AVX instructions are used in scalar version (process only one data element in vector registers).\nSince your execution units are vector units, only a vectorized loop can use their full power.\n",
                "title": "Vectorization",
                "txt": "Your loop is probably not vectorized.\nOnly 14% of vector register length is used (average across all SSE/AVX instructions).\nBy vectorizing your loop, you can lower the cost of an iteration from 84.00 to 10.50 cycles (8.00x speedup).",
              },
            ],
          "potential":
            [
              {
                "title": "Expensive FP math instructions/calls",
                "txt": "Detected performance impact from expensive FP math instructions/calls.\nBy removing/reexpressing them, you can lower the cost of an iteration from 84.00 to 36.75 cycles (2.29x speedup).",
              },
              {
                "workaround": "Try to change order in which elements are evaluated (using parentheses) in arithmetic expressions containing both ADD/SUB and MUL operations to enable your compiler to generate FMA instructions wherever possible.\nFor instance a + b*c is a valid FMA (MUL then ADD).\nHowever (a+b)* c cannot be translated into an FMA (ADD then MUL).",
                "title": "FMA",
                "txt": "Detected 24 FMA (fused multiply-add) operations.\nPresence of both ADD/SUB and MUL operations.",
              },
            ],
        },
      "paths":
        [
          {
            "hint":
              [
                {
                  "details": "These instructions generate more than one micro-operation and only one of them can be decoded during a cycle and the extra micro-operations increase pressure on execution units.\n - VCOMISS: 1 occurrences\n - VCVTTSS2SI: 12 occurrences\n",
                  "title": "Complex instructions",
                  "txt": "Detected COMPLEX INSTRUCTIONS.\n",
                },
                {
                  "workaround": "Avoid mixing data with different types. In particular, check if the type of constants is the same as array elements. Use double instead of single precision only when/where needed by numerical stability and avoid mixing precision. In C/C++, FP constants are double precision by default and must be suffixed by 'f' to make them single precision.",
                  "details": " - VCVTSS2SD (FP32 to FP64, scalar): 12 occurrences\n - VCVTTSS2SI (FP32 to INT32/64, scalar): 12 occurrences\n",
                  "title": "Conversion instructions",
                  "txt": "Detected expensive conversion instructions.",
                },
                {
                  "title": "Type of elements and instruction set",
                  "txt": "85 SSE or AVX instructions are processing arithmetic or math operations on single precision FP elements in scalar mode (one at a time).\n12 SSE or AVX instructions are processing arithmetic or math operations on double precision FP elements in scalar mode (one at a time).\n",
                },
                {
                  "title": "Matching between your loop (in the source code) and the binary loop",
                  "txt": "The binary loop is composed of 120 FP arithmetical operations:\n - 48: addition or subtraction (24 inside FMA instructions)\n - 48: multiply (24 inside FMA instructions)\n - 24: divide\nThe binary loop is loading 44 bytes (11 single precision FP elements).\nThe binary loop is storing 8 bytes (2 single precision FP elements).",
                },
                {
                  "title": "Arithmetic intensity",
                  "txt": "Arithmetic intensity is 2.31 FP operations per loaded or stored byte.",
                },
              ],
            "expert":
              [
                {
                  "title": "General properties",
                  "txt": "nb instructions    : 146\nnb uops            : 158\nloop length        : 652\nused x86 registers : 10\nused mmx registers : 0\nused xmm registers : 16\nused ymm registers : 0\nused zmm registers : 0\nnb stack references: 5\nADD-SUB / MUL ratio: 1.00\n",
                },
                {
                  "title": "Front-end",
                  "txt": "MACRO FUSION NOT POSSIBLE\nFIT IN UOP CACHE\nmicro-operation queue: 26.33 cycles\nfront end            : 26.33 cycles\n",
                },
                {
                  "title": "Back-end",
                  "txt": "       | ALU0/BRU0 | ALU1 | ALU2  | ALU3 | BRU1 | AGU0 | AGU1 | AGU2 | FP0   | FP1   | FP2   | FP3   | FP4  | FP5\n------------------------------------------------------------------------------------------------------------------\nuops   | 1.50      | 1.00 | 12.00 | 1.00 | 1.50 | 4.00 | 4.00 | 4.00 | 36.00 | 36.00 | 24.50 | 24.50 | 7.00 | 7.00\ncycles | 1.50      | 1.00 | 12.00 | 1.00 | 1.50 | 4.00 | 4.00 | 4.00 | 36.00 | 36.00 | 24.50 | 24.50 | 7.00 | 7.00\n\nExecution ports to units layout:\n - ALU0/BRU0: ALU\n - ALU1: ALU\n - ALU2: ALU\n - ALU3: ALU\n - BRU1: \n - AGU0 (256 bits): store address, load\n - AGU1 (256 bits): store address, load\n - AGU2 (256 bits): store address, load\n - FP0 (256 bits): VPU, DIV/SQRT\n - FP1 (256 bits): VPU, DIV/SQRT\n - FP2 (256 bits): VPU\n - FP3 (256 bits): VPU\n - FP4 (256 bits): FP store data\n - FP5 (256 bits): FP store data\n\nCycles executing div or sqrt instructions: 84.00\nCycles loading/storing data              : 5.50\nLongest recurrence chain latency (RecMII): 0.00\n",
                },
                {
                  "title": "Cycles summary",
                  "txt": "Front-end : 26.33\nDispatch  : 36.00\nDIV/SQRT  : 84.00\nData deps.: 0.00\nOverall L1: 84.00\n",
                },
                {
                  "title": "Vectorization ratios",
                  "txt": "INT\nall    : 0%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 0%\nFP\nall     : 3%\nload    : 0%\nstore   : 0%\nmul     : 0%\nadd-sub : 0%\nfma     : 0%\ndiv/sqrt: 0%\nother   : 13%\nINT+FP\nall     : 2%\nload    : 0%\nstore   : 0%\nmul     : 0%\nadd-sub : 0%\nfma     : 0%\ndiv/sqrt: 0%\nother   : 9%\n",
                },
                {
                  "title": "Vector efficiency ratios",
                  "txt": "INT\nall    : 12%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 12%\nFP\nall     : 14%\nload    : 12%\nstore   : 25%\nmul     : 12%\nadd-sub : 18%\nfma     : 12%\ndiv/sqrt: 12%\nother   : 17%\nINT+FP\nall     : 14%\nload    : 12%\nstore   : 25%\nmul     : 12%\nadd-sub : 18%\nfma     : 12%\ndiv/sqrt: 12%\nother   : 16%\n",
                },
                {
                  "title": "Cycles and memory resources usage",
                  "txt": "Assuming all data fit into the L1 cache, each iteration of the binary loop takes 84.00 cycles. At this rate:\n - 0% of peak load performance is reached (0.52 out of 96.00 bytes loaded per cycle (GB/s @ 1GHz))\n - 0% of peak store performance is reached (0.10 out of 64.00 bytes stored per cycle (GB/s @ 1GHz))\n",
                },
                {
                  "title": "Front-end bottlenecks",
                  "txt": "Found no such bottlenecks.",
                },
                {
                  "title": "ASM code",
                  "txt": "In the binary file, the address of the loop is: 24db\n\nInstruction                       | Nb FU | ALU0/BRU0 | ALU1 | ALU2 | ALU3 | BRU1 | AGU0 | AGU1 | AGU2 | FP0  | FP1  | FP2  | FP3  | FP4  | FP5  | Latency | Recip. throughput\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nVADDSS %XMM15,%XMM0,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMULSS %XMM15,%XMM0,%XMM6         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM8     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM8,%EAX             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMOVD %EAX,%XMM7                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM7,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM6,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVXORPD %XMM7,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0       | 0.17\nVFMADD231SS %XMM8,%XMM3,%XMM6     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM6,%XMM6,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM7,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM14,%XMM0,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM8     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM8,%EDX             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMOVD %EDX,%XMM7                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM7,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM14,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM13,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%ESI             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM13,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %ESI,%XMM8                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM12,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%R10D            | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM12,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %R10D,%XMM8                 | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM11,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%EAX             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM11,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EAX,%XMM8                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM10,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%EDX             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM10,%XMM0,%XMM7         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EDX,%XMM8                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM9,%XMM0,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%ESI             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM9,%XMM0,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %ESI,%XMM8                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0xc(%RSP),%XMM0,%XMM7      | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%R10D            | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0xc(%RSP),%XMM0,%XMM7      | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %R10D,%XMM8                 | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0x10(%RSP),%XMM0,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%EAX             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0x10(%RSP),%XMM0,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EAX,%XMM8                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0x14(%RSP),%XMM0,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%EDX             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0x14(%RSP),%XMM0,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EDX,%XMM8                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0x18(%RSP),%XMM0,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%ESI             | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0x18(%RSP),%XMM0,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %ESI,%XMM8                  | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMOVSS 0x1c(%RSP),%XMM8           | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50\nVADDSS %XMM8,%XMM0,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMULSS %XMM8,%XMM0,%XMM0          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%R10D            | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMOVD %R10D,%XMM7                 | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM7,%XMM7          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM0,%XMM1          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM1,%XMM2          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM7,%XMM3,%XMM2     | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM2,%XMM2,%XMM3       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM3,%XMM6          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMOVSD %XMM6,(%RDI,%RBP,2)        | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 1       | 1\nADD $0x4,%RBP                     | 1     | 0.25      | 0.25 | 0.25 | 0.25 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.25\nCMP %RBP,%R12                     | 1     | 0.25      | 0.25 | 0.25 | 0.25 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.25\nJE 2510 <kernel._omp_fn.0+0x3b0>  | 1     | 0.50      | 0    | 0    | 0    | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50-1\nVMOVSS (%R8,%RBP,1),%XMM0         | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50\nVXORPS %XMM3,%XMM3,%XMM3          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0       | 0.17\nVMOVSS (%R9,%RBP,1),%XMM1         | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50\nVCOMISS %XMM3,%XMM0               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 5       | 1\nJAE 2250 <kernel._omp_fn.0+0xf0>  | 1     | 0.50      | 0    | 0    | 0    | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50-1\nVXORPS %XMM3,%XMM3,%XMM3          | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0       | 0.17\nVMOVAPS %XMM3,%XMM2               | 0     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0       | 0.25\nJMP 2276 <kernel._omp_fn.0+0x116> | 1     | 0.50      | 0    | 0    | 0    | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0       | 1\n",
                },
              ],
            "header":
              [
              "2% of peak computational performance is used (1.43 out of 48.00 FLOP per cycle (GFLOPS @ 1GHz))",
              ],
            "brief":
              [
              ],
            "gain":
              [
                {
                  "workaround": " - Try another compiler or update/tune your current one:\n  * recompile with fassociative-math (included in Ofast or ffast-math) to extend loop vectorization to FP reductions.\n - Remove inter-iterations dependences from your loop and make it unit-stride:\n  * If your arrays have 2 or more dimensions, check whether elements are accessed contiguously and, otherwise, try to permute loops accordingly:\nC storage order is row-major: for(i) for(j) a[j][i] = b[j][i]; (slow, non stride 1) => for(i) for(j) a[i][j] = b[i][j]; (fast, stride 1)<<image_row_maj>>\n  * If your loop streams arrays of structures (AoS), try to use structures of arrays instead (SoA):\nfor(i) a[i].x = b[i].x; (slow, non stride 1) => for(i) a.x[i] = b.x[i]; (fast, stride 1)\n",
                  "details": "Store and arithmetical SSE/AVX instructions are used in scalar version (process only one data element in vector registers).\nSince your execution units are vector units, only a vectorized loop can use their full power.\n",
                  "title": "Vectorization",
                  "txt": "Your loop is probably not vectorized.\nOnly 14% of vector register length is used (average across all SSE/AVX instructions).\nBy vectorizing your loop, you can lower the cost of an iteration from 84.00 to 10.50 cycles (8.00x speedup).",
                },
                {
                  "workaround": " - Reduce the number of division or square root instructions:\n  * If denominator is constant over iterations, use reciprocal (replace x/y with x*(1/y)). Check precision impact. This will be done by your compiler with ffast-math or Ofast\n - If you accept to loose numerical precision up to 2 ulp, you can speedup your code by passing the following options to your compiler: (ffast-math or Ofast) and mrecip\n",
                  "title": "Execution units bottlenecks",
                  "txt": "Performance is limited by execution of divide and square root operations (the divide/square root unit is a bottleneck).\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 84.00 to 36.00 cycles (2.33x speedup).\n",
                },
              ],
            "potential":
              [
                {
                  "title": "Expensive FP math instructions/calls",
                  "txt": "Detected performance impact from expensive FP math instructions/calls.\nBy removing/reexpressing them, you can lower the cost of an iteration from 84.00 to 36.50 cycles (2.30x speedup).",
                },
                {
                  "workaround": "Try to change order in which elements are evaluated (using parentheses) in arithmetic expressions containing both ADD/SUB and MUL operations to enable your compiler to generate FMA instructions wherever possible.\nFor instance a + b*c is a valid FMA (MUL then ADD).\nHowever (a+b)* c cannot be translated into an FMA (ADD then MUL).",
                  "title": "FMA",
                  "txt": "Detected 24 FMA (fused multiply-add) operations.\nPresence of both ADD/SUB and MUL operations.",
                },
              ],
          },
          {
            "hint":
              [
                {
                  "details": "These instructions generate more than one micro-operation and only one of them can be decoded during a cycle and the extra micro-operations increase pressure on execution units.\n - VCOMISS: 1 occurrences\n - VCVTTSS2SI: 12 occurrences\n",
                  "title": "Complex instructions",
                  "txt": "Detected COMPLEX INSTRUCTIONS.\n",
                },
                {
                  "workaround": "Avoid mixing data with different types. In particular, check if the type of constants is the same as array elements. Use double instead of single precision only when/where needed by numerical stability and avoid mixing precision. In C/C++, FP constants are double precision by default and must be suffixed by 'f' to make them single precision.",
                  "details": " - VCVTSS2SD (FP32 to FP64, scalar): 12 occurrences\n - VCVTTSS2SI (FP32 to INT32/64, scalar): 12 occurrences\n",
                  "title": "Conversion instructions",
                  "txt": "Detected expensive conversion instructions.",
                },
                {
                  "title": "Type of elements and instruction set",
                  "txt": "86 SSE or AVX instructions are processing arithmetic or math operations on single precision FP elements in scalar mode (one at a time).\n12 SSE or AVX instructions are processing arithmetic or math operations on double precision FP elements in scalar mode (one at a time).\n",
                },
                {
                  "title": "Matching between your loop (in the source code) and the binary loop",
                  "txt": "The binary loop is composed of 120 FP arithmetical operations:\n - 48: addition or subtraction (24 inside FMA instructions)\n - 48: multiply (24 inside FMA instructions)\n - 24: divide\nThe binary loop is loading 52 bytes (13 single precision FP elements).\nThe binary loop is storing 8 bytes (2 single precision FP elements).",
                },
                {
                  "title": "Arithmetic intensity",
                  "txt": "Arithmetic intensity is 2.00 FP operations per loaded or stored byte.",
                },
              ],
            "expert":
              [
                {
                  "title": "General properties",
                  "txt": "nb instructions    : 149\nnb uops            : 162\nloop length        : 677\nused x86 registers : 12\nused mmx registers : 0\nused xmm registers : 16\nused ymm registers : 0\nused zmm registers : 0\nnb stack references: 5\nADD-SUB / MUL ratio: 1.00\n",
                },
                {
                  "title": "Front-end",
                  "txt": "MACRO FUSION NOT POSSIBLE\nFIT IN UOP CACHE\nmicro-operation queue: 27.00 cycles\nfront end            : 27.00 cycles\n",
                },
                {
                  "title": "Back-end",
                  "txt": "       | ALU0/BRU0 | ALU1 | ALU2  | ALU3 | BRU1 | AGU0 | AGU1 | AGU2 | FP0   | FP1   | FP2   | FP3   | FP4  | FP5\n------------------------------------------------------------------------------------------------------------------\nuops   | 1.00      | 1.00 | 14.00 | 1.00 | 1.00 | 4.67 | 4.67 | 4.67 | 37.00 | 37.00 | 25.00 | 25.00 | 7.00 | 7.00\ncycles | 1.00      | 1.00 | 14.00 | 1.00 | 1.00 | 4.67 | 4.67 | 4.67 | 37.00 | 37.00 | 25.00 | 25.00 | 7.00 | 7.00\n\nExecution ports to units layout:\n - ALU0/BRU0: ALU\n - ALU1: ALU\n - ALU2: ALU\n - ALU3: ALU\n - BRU1: \n - AGU0 (256 bits): store address, load\n - AGU1 (256 bits): store address, load\n - AGU2 (256 bits): store address, load\n - FP0 (256 bits): VPU, DIV/SQRT\n - FP1 (256 bits): VPU, DIV/SQRT\n - FP2 (256 bits): VPU\n - FP3 (256 bits): VPU\n - FP4 (256 bits): FP store data\n - FP5 (256 bits): FP store data\n\nCycles executing div or sqrt instructions: 84.00\nCycles loading/storing data              : 6.50\nLongest recurrence chain latency (RecMII): 0.00\n",
                },
                {
                  "title": "Cycles summary",
                  "txt": "Front-end : 27.00\nDispatch  : 37.00\nDIV/SQRT  : 84.00\nData deps.: 0.00\nOverall L1: 84.00\n",
                },
                {
                  "title": "Vectorization ratios",
                  "txt": "INT\nall    : 0%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 0%\nFP\nall     : 3%\nload    : 0%\nstore   : 0%\nmul     : 0%\nadd-sub : 0%\nfma     : 0%\ndiv/sqrt: 0%\nother   : 13%\nINT+FP\nall     : 2%\nload    : 0%\nstore   : 0%\nmul     : 0%\nadd-sub : 0%\nfma     : 0%\ndiv/sqrt: 0%\nother   : 9%\n",
                },
                {
                  "title": "Vector efficiency ratios",
                  "txt": "INT\nall    : 12%\nload   : NA (no load vectorizable/vectorized instructions)\nstore  : NA (no store vectorizable/vectorized instructions)\nmul    : NA (no mul vectorizable/vectorized instructions)\nadd-sub: NA (no add-sub vectorizable/vectorized instructions)\nfma    : NA (no fma vectorizable/vectorized instructions)\nother  : 12%\nFP\nall     : 14%\nload    : 12%\nstore   : 25%\nmul     : 12%\nadd-sub : 18%\nfma     : 12%\ndiv/sqrt: 12%\nother   : 17%\nINT+FP\nall     : 14%\nload    : 12%\nstore   : 25%\nmul     : 12%\nadd-sub : 18%\nfma     : 12%\ndiv/sqrt: 12%\nother   : 15%\n",
                },
                {
                  "title": "Cycles and memory resources usage",
                  "txt": "Assuming all data fit into the L1 cache, each iteration of the binary loop takes 84.00 cycles. At this rate:\n - 0% of peak load performance is reached (0.62 out of 96.00 bytes loaded per cycle (GB/s @ 1GHz))\n - 0% of peak store performance is reached (0.10 out of 64.00 bytes stored per cycle (GB/s @ 1GHz))\n",
                },
                {
                  "title": "Front-end bottlenecks",
                  "txt": "Found no such bottlenecks.",
                },
                {
                  "title": "ASM code",
                  "txt": "In the binary file, the address of the loop is: 24db\n\nInstruction                         | Nb FU | ALU0/BRU0 | ALU1 | ALU2 | ALU3 | BRU1 | AGU0 | AGU1 | AGU2 | FP0  | FP1  | FP2  | FP3  | FP4  | FP5  | Latency | Recip. throughput\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nVMOVSS 0xdac(%RIP),%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50\nVCMPSS $0x1,0xda3(%RIP),%XMM0,%XMM8 | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 1       | 0.50\nVMOVD %R11D,%XMM7                   | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVMOVD %ECX,%XMM2                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVBLENDVPS %XMM8,%XMM6,%XMM7,%XMM3   | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 1       | 0.50\nVBLENDVPS %XMM8,%XMM2,%XMM6,%XMM2   | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 1       | 0.50\nVADDSS %XMM15,%XMM0,%XMM8           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMULSS %XMM15,%XMM0,%XMM6           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM8,%EAX               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMOVD %EAX,%XMM7                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM7,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM6,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVXORPD %XMM7,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0       | 0.17\nVFMADD231SS %XMM8,%XMM3,%XMM6       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM6,%XMM6,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM7,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM14,%XMM0,%XMM8           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM8       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM8,%EDX               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMOVD %EDX,%XMM7                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM7,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM14,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM13,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%ESI               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM13,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %ESI,%XMM8                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM12,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%R10D              | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM12,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %R10D,%XMM8                   | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM11,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%EAX               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM11,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EAX,%XMM8                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM10,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%EDX               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM10,%XMM0,%XMM7           | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EDX,%XMM8                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS %XMM9,%XMM0,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVCVTTSS2SI %XMM7,%ESI               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS %XMM9,%XMM0,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %ESI,%XMM8                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0xc(%RSP),%XMM0,%XMM7        | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%R10D              | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0xc(%RSP),%XMM0,%XMM7        | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %R10D,%XMM8                   | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0x10(%RSP),%XMM0,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%EAX               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0x10(%RSP),%XMM0,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EAX,%XMM8                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0x14(%RSP),%XMM0,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%EDX               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0x14(%RSP),%XMM0,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %EDX,%XMM8                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSS 0x18(%RSP),%XMM0,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%ESI               | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMULSS 0x18(%RSP),%XMM0,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVMOVD %ESI,%XMM8                    | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM8,%XMM8            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM8,%XMM3,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM7,%XMM7,%XMM8         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM8,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMOVSS 0x1c(%RSP),%XMM8             | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50\nVADDSS %XMM8,%XMM0,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMULSS %XMM8,%XMM0,%XMM0            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD132SS %XMM5,%XMM4,%XMM7       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTTSS2SI %XMM7,%R10D              | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 4       | 1\nVMOVD %R10D,%XMM7                   | 1     | 0         | 0    | 1    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2       | 1\nVDIVSS %XMM1,%XMM7,%XMM7            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVDIVSS %XMM1,%XMM0,%XMM1            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 10      | 3.50\nVMULSS %XMM2,%XMM1,%XMM2            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 3       | 0.50\nVFMADD231SS %XMM7,%XMM3,%XMM2       | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 4       | 0.50\nVCVTSS2SD %XMM2,%XMM2,%XMM3         | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVADDSD %XMM6,%XMM3,%XMM6            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 3       | 0.50\nVMOVSD %XMM6,(%RDI,%RBP,2)          | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 1       | 1\nADD $0x4,%RBP                       | 1     | 0.25      | 0.25 | 0.25 | 0.25 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.25\nCMP %RBP,%R12                       | 1     | 0.25      | 0.25 | 0.25 | 0.25 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.25\nJE 2510 <kernel._omp_fn.0+0x3b0>    | 1     | 0.50      | 0    | 0    | 0    | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50-1\nVMOVSS (%R8,%RBP,1),%XMM0           | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50\nVXORPS %XMM3,%XMM3,%XMM3            | 1     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0       | 0.17\nVMOVSS (%R9,%RBP,1),%XMM1           | 1     | 0         | 0    | 0    | 0    | 0    | 0.33 | 0.33 | 0.33 | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50\nVCOMISS %XMM3,%XMM0                 | 2     | 0         | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0.50 | 0.50 | 0.50 | 0.50 | 5       | 1\nJAE 2250 <kernel._omp_fn.0+0xf0>    | 1     | 0.50      | 0    | 0    | 0    | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 1       | 0.50-1\n",
                },
              ],
            "header":
              [
              "2% of peak computational performance is used (1.43 out of 48.00 FLOP per cycle (GFLOPS @ 1GHz))",
              ],
            "brief":
              [
              ],
            "gain":
              [
                {
                  "workaround": " - Try another compiler or update/tune your current one:\n  * recompile with fassociative-math (included in Ofast or ffast-math) to extend loop vectorization to FP reductions.\n - Remove inter-iterations dependences from your loop and make it unit-stride:\n  * If your arrays have 2 or more dimensions, check whether elements are accessed contiguously and, otherwise, try to permute loops accordingly:\nC storage order is row-major: for(i) for(j) a[j][i] = b[j][i]; (slow, non stride 1) => for(i) for(j) a[i][j] = b[i][j]; (fast, stride 1)<<image_row_maj>>\n  * If your loop streams arrays of structures (AoS), try to use structures of arrays instead (SoA):\nfor(i) a[i].x = b[i].x; (slow, non stride 1) => for(i) a.x[i] = b.x[i]; (fast, stride 1)\n",
                  "details": "Store and arithmetical SSE/AVX instructions are used in scalar version (process only one data element in vector registers).\nSince your execution units are vector units, only a vectorized loop can use their full power.\n",
                  "title": "Vectorization",
                  "txt": "Your loop is probably not vectorized.\nOnly 14% of vector register length is used (average across all SSE/AVX instructions).\nBy vectorizing your loop, you can lower the cost of an iteration from 84.00 to 10.50 cycles (8.00x speedup).",
                },
                {
                  "workaround": " - Reduce the number of division or square root instructions:\n  * If denominator is constant over iterations, use reciprocal (replace x/y with x*(1/y)). Check precision impact. This will be done by your compiler with ffast-math or Ofast\n - If you accept to loose numerical precision up to 2 ulp, you can speedup your code by passing the following options to your compiler: (ffast-math or Ofast) and mrecip\n",
                  "title": "Execution units bottlenecks",
                  "txt": "Performance is limited by execution of divide and square root operations (the divide/square root unit is a bottleneck).\n\nBy removing all these bottlenecks, you can lower the cost of an iteration from 84.00 to 37.00 cycles (2.27x speedup).\n",
                },
              ],
            "potential":
              [
                {
                  "title": "Expensive FP math instructions/calls",
                  "txt": "Detected performance impact from expensive FP math instructions/calls.\nBy removing/reexpressing them, you can lower the cost of an iteration from 84.00 to 37.00 cycles (2.27x speedup).",
                },
                {
                  "workaround": "Try to change order in which elements are evaluated (using parentheses) in arithmetic expressions containing both ADD/SUB and MUL operations to enable your compiler to generate FMA instructions wherever possible.\nFor instance a + b*c is a valid FMA (MUL then ADD).\nHowever (a+b)* c cannot be translated into an FMA (ADD then MUL).",
                  "title": "FMA",
                  "txt": "Detected 24 FMA (fused multiply-add) operations.\nPresence of both ADD/SUB and MUL operations.",
                },
              ],
          },
        ],
      "common":
        {
          "header":
            [
            "The loop is defined in /home/sofiane/AOC/tp-rendu/AOC/kernel.c:13,123-135.\n",
            "The related source loop is not unrolled or unrolled with no peel/tail loop.",
            "The structure of this loop is probably <if then [else] end>.\n",
            "The presence of multiple execution paths is typically the main/first bottleneck.\nTry to simplify control inside loop: ideally, try to remove all conditional expressions, for example by (if applicable):\n - hoisting them (moving them outside the loop)\n - turning them into conditional moves, MIN or MAX\n\n",
            "Ex: if (x<0) x=0 => x = (x<0 ? 0 : x) (or MAX(0,x) after defining the corresponding macro)\n",
            ],
          "nb_paths": 2,
        },
    },
}
